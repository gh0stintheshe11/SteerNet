{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_segment = 'data/comma2k19/extracted/Chunk_1/b0c9d2329ad1606b|2018-07-27--06-03-57/3/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "from numpy import pi\n",
    "%matplotlib inline\n",
    "from matplotlib.pyplot import figure, plot, title, legend, xlabel, ylabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')\n",
    "os.listdir(example_segment) # all the files present for every minute of driving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot the speed from a variety of sources\n",
    "figure(figsize=(10,10))\n",
    "\n",
    "# from can data\n",
    "plot(np.load(example_segment + 'processed_log/CAN/speed/t'),\n",
    "     np.load(example_segment + 'processed_log/CAN/speed/value'),\n",
    "     label='CAN');\n",
    "\n",
    "# from qcom gnss data\n",
    "plot(np.load(example_segment + 'processed_log/GNSS/live_gnss_qcom/t'),\n",
    "     np.load(example_segment + 'processed_log/GNSS/live_gnss_qcom/value')[:,2],\n",
    "     label='live qcom fix');\n",
    "\n",
    "# from u-blox gnss data\n",
    "plot(np.load(example_segment + 'processed_log/GNSS/live_gnss_ublox/t'),\n",
    "     np.load(example_segment + 'processed_log/GNSS/live_gnss_ublox/value')[:,2],\n",
    "     label='live u-blox live fix');\n",
    "\n",
    "# from post-processed data\n",
    "plot(np.load(example_segment + 'global_pose/frame_times'),\n",
    "     np.linalg.norm(np.load(example_segment + 'global_pose/frame_velocities'),axis=1), linewidth=4,\n",
    "     label='post-processed poses');\n",
    "\n",
    "title('Speed from various sources', fontsize=14);\n",
    "legend(fontsize=14);\n",
    "xlabel('boot time (s)', fontsize=12);\n",
    "ylabel('speed (m/s)', fontsize=12);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can plot the yaw rate and compare it to the steering angle\n",
    "# This segment doesn't have much turning, if it did we would see\n",
    "# very clear negative correlation, now we only see it at about\n",
    "# 12s into the segment.\n",
    "figure(figsize=(10,10));\n",
    "\n",
    "# yaw rate from gyro\n",
    "plot(np.load(example_segment + 'processed_log/IMU/gyro/t'),\n",
    "     (180/pi)*np.load(example_segment + 'processed_log/IMU/gyro/value')[:,2],\n",
    "     label='gyro');\n",
    "\n",
    "# from can data we\n",
    "plot(np.load(example_segment + 'processed_log/CAN/steering_angle/t'),\n",
    "     np.load(example_segment + 'processed_log/CAN/steering_angle/value'), linewidth=4,\n",
    "     label='steering angle from CAN')\n",
    "\n",
    "\n",
    "title('Yaw rate vs steering angle', fontsize=14);\n",
    "legend(fontsize=14);\n",
    "xlabel('boot time (s)', fontsize=12);\n",
    "ylabel('Yaw rate (deg/s) or steering angle (deg)', fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils.orientation as orient\n",
    "import utils.coordinates as coord\n",
    "\n",
    "# we can plot the orientation of the camera in \n",
    "# euler angles respective to the local ground plane,\n",
    "# i.e. the North East Down reference frame. This is more\n",
    "# intuitive than the quaternion.\n",
    "\n",
    "figure(figsize=(10,10));\n",
    "\n",
    "frame_times = np.load(example_segment + 'global_pose/frame_times')\n",
    "frame_positions = np.load(example_segment + 'global_pose/frame_positions')\n",
    "frame_orientations = np.load(example_segment + 'global_pose/frame_orientations')\n",
    "euler_angles_ned_deg = (180/pi)*orient.ned_euler_from_ecef(frame_positions[0], orient.euler_from_quat(frame_orientations))\n",
    "\n",
    "\n",
    "plot(frame_times, euler_angles_ned_deg[:,0], label='roll', linewidth=3);\n",
    "plot(frame_times, euler_angles_ned_deg[:,1], label='pitch', linewidth=3);\n",
    "plot(frame_times, euler_angles_ned_deg[:,2], label='yaw', linewidth=3);\n",
    "title('Orientation in local frame (NED)', fontsize=14);\n",
    "legend(fontsize=14);\n",
    "xlabel('boot time (s)', fontsize=12);\n",
    "ylabel('Euler angle (deg)', fontsize=12);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can project the path driven onto the first image\n",
    "\n",
    "# first we convert the frame_positions to the frame\n",
    "# defined by the pose of the first frame\n",
    "ecef_from_local = orient.rot_from_quat(frame_orientations[0])\n",
    "local_from_ecef = ecef_from_local.T\n",
    "frame_positions_local = np.einsum('ij,kj->ki', local_from_ecef, frame_positions - frame_positions[0])\n",
    "\n",
    "from utils.camera import img_from_device, denormalize, view_frame_from_device_frame\n",
    "\n",
    "def draw_path(device_path, img, width=1, height=1.2, fill_color=(128,0,255), line_color=(0,255,0)):\n",
    "  device_path_l = device_path + np.array([0, 0, height])                                                                    \n",
    "  device_path_r = device_path + np.array([0, 0, height])                                                                    \n",
    "  device_path_l[:,1] -= width                                                                                               \n",
    "  device_path_r[:,1] += width\n",
    "\n",
    "  img_points_norm_l = img_from_device(device_path_l)\n",
    "  img_points_norm_r = img_from_device(device_path_r)\n",
    "  img_pts_l = denormalize(img_points_norm_l)\n",
    "  img_pts_r = denormalize(img_points_norm_r)\n",
    "\n",
    "  # filter out things rejected along the way\n",
    "  valid = np.logical_and(np.isfinite(img_pts_l).all(axis=1), np.isfinite(img_pts_r).all(axis=1))\n",
    "  img_pts_l = img_pts_l[valid].astype(int)\n",
    "  img_pts_r = img_pts_r[valid].astype(int)\n",
    "\n",
    "  for i in range(1, len(img_pts_l)):\n",
    "    u1,v1,u2,v2 = np.append(img_pts_l[i-1], img_pts_r[i-1])\n",
    "    u3,v3,u4,v4 = np.append(img_pts_l[i], img_pts_r[i])\n",
    "    pts = np.array([[u1,v1],[u2,v2],[u4,v4],[u3,v3]], np.int32).reshape((-1,1,2))\n",
    "    cv2.fillPoly(img,[pts],fill_color)\n",
    "    cv2.polylines(img,[pts],True,line_color)\n",
    "\n",
    "import cv2\n",
    "\n",
    "img = imread(example_segment + 'preview.png')\n",
    "draw_path(frame_positions_local[11:250], img)\n",
    "figsize(12,12);\n",
    "imshow(img);\n",
    "title('Driven path projected onto first image', fontsize=25);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
